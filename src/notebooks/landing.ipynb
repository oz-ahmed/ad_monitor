{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f99f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ad_stream(\n",
    "    volume_path: str,\n",
    "    stream_type: str,\n",
    "    advertiser_count: int,\n",
    "    batch_interval_s: int,\n",
    "    latency_max_s: int):\n",
    "    \"\"\"\n",
    "    Simulates real-time data generation for an ad platform.\n",
    "\n",
    "    Args:\n",
    "        volume_path (str): The full path to the Volume where data will be saved (e.g., /Volumes/catalog/schema/landing).\n",
    "        stream_type (str): The type of data to generate. Must be either 'paid_event' or 'budget_change'.\n",
    "        advertiser_count (int): The number of distinct advertisers to simulate.\n",
    "        batch_interval_s (int): The time interval in seconds between generating batches of data.\n",
    "        latency_max_s (int): The maximum random latency to simulate event time.\n",
    "    \"\"\"\n",
    "    print(f\"ðŸš€ Starting '{stream_type}' stream generator for path: {volume_path}\")\n",
    "    \n",
    "    while True:\n",
    "        now = datetime.now(timezone.utc)\n",
    "        data = []\n",
    "        \n",
    "        # Generate a batch of random events\n",
    "        for _ in range(1, advertiser_count + 1):\n",
    "            advertiser_id = random.randint(1, advertiser_count + 1)\n",
    "            moment = now\n",
    "            \n",
    "            if stream_type == 'paid_event':\n",
    "                # Simulate a paid click event\n",
    "                amount = round(random.uniform(1.00, 1.40), 2)\n",
    "                record = {\n",
    "                    \"advertiser_id\": advertiser_id,\n",
    "                    \"moment\": moment,\n",
    "                    \"amount\": amount\n",
    "                }\n",
    "                data.append(record)\n",
    "            \n",
    "            elif stream_type == 'budget_change':\n",
    "                # Simulate a budget change event\n",
    "                new_budget = round(random.uniform(10.00, 30.00), 2)\n",
    "                record = {\n",
    "                    \"advertiser_id\": advertiser_id,\n",
    "                    \"moment\": moment,\n",
    "                    \"new_budget_value\": new_budget\n",
    "                }\n",
    "                data.append(record)\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(\"Invalid stream_type. Choose 'paid_event' or 'budget_change'.\")\n",
    "\n",
    "        # Create a Spark DataFrame from the generated data\n",
    "        if not data:\n",
    "            print(\"No data generated in this batch. Skipping write.\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            df = spark.createDataFrame(data)\n",
    "            \n",
    "            # Write the DataFrame to the specified Delta path in append mode\n",
    "            df.write.format(\"delta\").mode(\"append\").save(volume_path)\n",
    "            print(f\"Successfully wrote {len(data)} records to {volume_path} at {now.isoformat()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error writing to Spark: {e}\")\n",
    "\n",
    "        # Wait for the next interval\n",
    "        time.sleep(batch_interval_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a133f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration for Running the Generators ---\n",
    "\n",
    "# IMPORTANT: Replace these with your actual Catalog and Schema names\n",
    "CATALOG_NAME = \"ad_monitor\"\n",
    "SCHEMA_NAME = \"landing\"\n",
    "\n",
    "# Settings for the data streams\n",
    "advertiser_count = 5      # Simulate 5 different advertisers\n",
    "batch_interval_s = 300      # Generate a new batch of data every 300 seconds\n",
    "latency_max_s = 120         # Simulate a max latency of 60 seconds\n",
    "\n",
    "# Define the streams to run: (volume_path, stream_type)\n",
    "streams_to_run = [\n",
    "    (f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/paid_events_stream\", 'paid_event'),\n",
    "    (f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/budget_changes_stream\", 'budget_change')\n",
    "]\n",
    "\n",
    "# --- Launch Generators Concurrently --\n",
    "# Using ThreadPoolExecutor to run the infinite generator functions in parallel threads.\n",
    "# This cell runs indefinitely. To stop it, interrupt or detach the notebook from the cluster.\n",
    "print(\"Starting concurrent stream generation. Interrupt the kernel to stop.\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(streams_to_run)) as executor:\n",
    "    for path, stream_type in streams_to_run:\n",
    "        executor.submit(\n",
    "            generate_ad_stream,\n",
    "            path,\n",
    "            stream_type,\n",
    "            advertiser_count,\n",
    "            batch_interval_s,\n",
    "            latency_max_s\n",
    "        )\n",
    "    # The context manager will block here because the submitted tasks are infinite loops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64163529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad-monitor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
